{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da43935-fb9d-431c-ace0-1ec7aaac9e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:09<00:00, 25.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for 5 batches.\n",
      "Batch 1: 3 images, 3 labels.\n",
      "Batch 2: 3 images, 3 labels.\n",
      "Batch 3: 3 images, 3 labels.\n",
      "Batch 4: 3 images, 3 labels.\n",
      "Batch 5: 3 images, 3 labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing the cifar dataset.\n",
    "def unpickle(file):\n",
    "    with open(file, mode = \"rb\") as fil:\n",
    "        try:\n",
    "            temp_dict = pickle.load(fil, encoding = \"bytes\")\n",
    "            return temp_dict\n",
    "        except Exception as e:\n",
    "            print(f\"An error occured while loading: {e}\")\n",
    "            return None\n",
    "\n",
    "mod_dict = {1:[],2:[],3:[],4:[],5:[]}\n",
    "class data_prep:\n",
    "    label_path = \"/Users/Vedant Dutta/Desktop/CIFAR_10/batches.meta\"\n",
    "    root_path = \"/Users/Vedant Dutta/Desktop/CIFAR_10\"\n",
    "    training_dict = {1:'data_batch_1', 2:'data_batch_2', 3:'data_batch_3', 4:'data_batch_4',5:'data_batch_5'}\n",
    "    label_dict = unpickle(label_path)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "                                      transforms.Resize((224,224)),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "                                      \n",
    "\n",
    "    '''this is of the form, label_dict[0] = \"Airplane\"'''\n",
    "    for num in tqdm(training_dict.keys()):\n",
    "        new_path = os.path.join(root_path,training_dict[num])\n",
    "        if not os.path.exists(new_path):\n",
    "            print(\"error occured while joining paths for bactch num : {}\".format(num))\n",
    "        if unpickle(new_path) == None:\n",
    "            print(\"Error loading the data\")\n",
    "        else:\n",
    "            temp_data_dict = unpickle(new_path)\n",
    "            '''the dict is of the following form : a 10,000X3072 numpy array, where for each row\n",
    "            the first 1024 values are for channel1 and so on.\n",
    "            ->The corresponding values of the dictionary are the labels for each of the pictures'''\n",
    "            data_list = []\n",
    "            labl_list = []\n",
    "            data_array = np.array(temp_data_dict[b'data']).astype(np.float32) / 255.0\n",
    "            for data, label_val in zip(data_array, temp_data_dict[b'labels']):\n",
    "                d_tensor = torch.from_numpy(data).view(3, 32, 32)\n",
    "                d_tensor_resized = transformer(d_tensor)  # Now you can apply transformer directly\n",
    "                data_list.append(d_tensor_resized)\n",
    "                labl_list.append(label_val)\n",
    "            mod_dict[num] = (data_list, labl_list)\n",
    "    \n",
    "                \n",
    "data_class = data_prep()\n",
    "print(f\"Loaded data for {len(mod_dict)} batches.\")\n",
    "\n",
    "for num, data in mod_dict.items():\n",
    "    if data:  \n",
    "        print(f\"Batch {num}: {len(data[0][0])} images, {len(data[0][1])} labels.\")\n",
    "    else:\n",
    "        print(f\"Batch {num} is empty.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48346cea-8a26-4e76-ab7e-2d30f69aba4d",
   "metadata": {},
   "source": [
    "The data has now been prepared for each of the batches and it going to be used to train the VGGnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94267b60-61f1-483e-b112-c7144c14582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGGNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512 *7*7, 4096), \n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Linear(4096, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the output\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8bdae1-cb04-4055-a519-523321618b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████                                                                 | 211/1563 [1:17:31<7:05:39, 18.89s/it]"
     ]
    }
   ],
   "source": [
    "#training the model.\n",
    "import torch.optim as optim\n",
    "\n",
    "def aggregate_data(data_dict):\n",
    "    train_data = []\n",
    "    labl_arr = []\n",
    "    for num in range(1,6):\n",
    "        if data_dict[num]:\n",
    "            data_list = data_dict[num][0]\n",
    "            label_arr = data_dict[num][1]\n",
    "            train_data.extend(data_list)\n",
    "            labl_arr.extend(label_arr)   #this was initially append.\n",
    "    return train_data, labl_arr\n",
    "\n",
    "#we can now combine and then shuffle the data.\n",
    "train_data,train_labels = aggregate_data(mod_dict)\n",
    "indices = np.arange(len(train_data))\n",
    "np.random.shuffle(indices)\n",
    "shuffled_data = [train_data[i] for i in indices]\n",
    "shuffled_labels = [train_labels[i] for i in indices]  #should be train_labels.\n",
    "\n",
    "def training_func(model, data, num_epochs, optimizer, loss_func, batch_size):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss =0\n",
    "        for i in tqdm(range(0, len(data[0]), batch_size)):\n",
    "            images = data[0][i:i + batch_size]\n",
    "            labels = data[1][i:i + batch_size]\n",
    "            images = torch.stack(images)\n",
    "            labels = torch.tensor(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  #maybe forward should be removed.\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss / (len(data[0]) // batch_size):.4f}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = VGGNet(num_classes = 10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "training_func(model, (shuffled_data, shuffled_labels), num_epochs=2, optimizer=optimizer, loss_func=criterion, batch_size=32)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e7dcbf8e-2721-4a89-91fa-89d98c595156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "train_data = aggregate_data(mod_dict)\n",
    "indices = np.arange(len(train_data[0]))\n",
    "np.random.shuffle(indices)\n",
    "shuffled_data = [train_data[0][i] for i in indices]\n",
    "shuffled_labels = [train_data[1][i] for i in indices]\n",
    "print(len(shuffled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "118006b2-a924-4c95-8255-07cb261839f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e447c20-bb20-4efa-91aa-7bdaafabb12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560256\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcb5a36-b531-4bd5-8daf-b324f570ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: 10000 images, 10000 labels\n",
      "Batch 2: 10000 images, 10000 labels\n",
      "Batch 3: 10000 images, 10000 labels\n",
      "Batch 4: 10000 images, 10000 labels\n",
      "Batch 5: 10000 images, 10000 labels\n",
      "Total training data: 50000, Total labels: 50000\n",
      "Number of training samples: 50000\n",
      "Number of labels: 50000\n"
     ]
    }
   ],
   "source": [
    "def aggregate_data(data_dict):\n",
    "    train_data = []\n",
    "    labl_arr = []\n",
    "    for num in range(1, 6):\n",
    "        if data_dict[num]:\n",
    "            data_list = data_dict[num][0]\n",
    "            label_arr = data_dict[num][0]\n",
    "            print(f\"Batch {num}: {len(data_list)} images, {len(label_arr)} labels\")  # Debugging line\n",
    "            train_data.extend(data_list)\n",
    "            labl_arr.extend(label_arr)\n",
    "    print(f\"Total training data: {len(train_data)}, Total labels: {len(labl_arr)}\")  # Debugging line\n",
    "    return train_data, labl_arr\n",
    "\n",
    "# Aggregate data from batches\n",
    "train_data, train_labels = aggregate_data(mod_dict)\n",
    "\n",
    "# Check lengths\n",
    "print(f\"Number of training samples: {len(train_data)}\")  # Should be 50000\n",
    "print(f\"Number of labels: {len(train_labels)}\")  # Should also be 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9f131f-6b74-4022-af3d-0a8c82e668dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(mod_dict[5][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7efead-6d6d-4035-bcde-c5a3ddb4eb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb1fcb-1fc6-490b-b971-1c11a8b9bf87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
